
# Quantum Transformer

Nowadays, Transformer models are ubiquitous and dominant in the analysis of sequential data. Pre-trained models such as GPT-3 are hard to train and have hundreds of billions of parameters. On the Other hand, quantum computing has developed recently in terms of hardware and algorithm implementation. Recent articles indicate quantum advantages for deploying some learning algorithms, such as support vector machines, even on near-term quantum devices. Based on that, I wrote tutorial on how to build and train quantum-enhanced transformers with the Torch-Quantum library.


## Authors



- [@MohammadrezaTavasoli](https://github.com/MohammadrezaTavasoli)
